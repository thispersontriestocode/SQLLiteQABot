{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70a45886-819d-42bb-bea7-6443abb6cf2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains'), (6, 'Ant√¥nio Carlos Jobim'), (7, 'Apocalyptica'), (8, 'Audioslave'), (9, 'BackBeat'), (10, 'Billy Cobham')]\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain_community.agent_toolkits import SQLDatabaseToolkit\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDatabaseTool\n",
    "import re\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_ollama import OllamaLLM\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n",
    "db.run(\"SELECT * FROM Artist LIMIT 10;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12301bb4-b501-4d96-9330-e39b3e4445fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: str\n",
    "    result: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f1246f5-ced4-4a08-b015-daf19717511e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load Mistral from Ollama\n",
    "llm = OllamaLLM(model=\"mistral\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be396196-6f5b-43cd-b2f5-ec4b9da21d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "query_prompt_template = PromptTemplate(\n",
    "    input_variables=[\"query\", \"dialect\", \"top_k\"],\n",
    "    template=\"\"\"Given an input question, create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer.\n",
    "Unless the user specifies a specific number of examples they wish to obtain, always limit your query to at most {top_k} results.\n",
    "You can order the results by a relevant column to return the most interesting examples in the database.\n",
    "Never query for all the columns from a specific table, only ask for the relevant columns given the question.\n",
    "\n",
    "Pay attention to use only the column names that you can see in the schema description. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
    "\n",
    "\n",
    "**Instructions:**\n",
    "- You MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\n",
    "- DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\n",
    "- **Always** use column names explicitly (e.g., `COUNT(EmployeeId) AS EmployeeCount` instead of `COUNT(*)`).\n",
    "- Do **not** explain the query.\n",
    "- Do **not** include any additional text.\n",
    "- Do **not** describe database tables unless explicitly asked.\n",
    "- Only return the final SQL query.\n",
    "- Always limit results to **{top_k}** unless specified otherwise.\n",
    "- Do **not** add anything to the end of the table name (e.g 'Employee' instead of 'Employees'\n",
    "\n",
    "To start you should ALWAYS look at the tables in the database to see what you can query.\n",
    "Do NOT skip this step.\n",
    "Then you should query the schema of the most relevant tables.\n",
    "\n",
    "\n",
    "\n",
    "**User Question:** {query}\n",
    "\n",
    "**SQL Query Output:**\n",
    "```sql\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b78c7c2-c6e9-494e-8213-9bdf95b8c8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_sql_query(text):\n",
    "    \"\"\"Extract SQL query from the LLM response.\"\"\"\n",
    "    match = re.search(r\"```sql\\n(.*?)\\n```\", text, re.DOTALL)\n",
    "    return match.group(1) if match else text.strip()\n",
    "\n",
    "def write_query(state):\n",
    "    \"\"\"Generate a SQL query using the refined prompt.\"\"\"\n",
    "    prompt = query_prompt_template.format(\n",
    "        query=state[\"question\"],\n",
    "        dialect=db.dialect,\n",
    "        top_k=5\n",
    "    )\n",
    "\n",
    "    result = llm.invoke(prompt)\n",
    "\n",
    "    return {\"query\": extract_sql_query(result)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7f2e7f5-94ff-482f-8bd8-c44d06d58f5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResponseError",
     "evalue": "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\"\n\"http://www.w3.org/TR/html4/loose.dtd\">\n<html>\n<head>\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n<title>Notification: Proxy Authorization Required</title>\n<style type=\"text/css\">\nbody {\n  font-family: Arial, Helvetica, sans-serif;\n  font-size: 14px;\n  color:#333333;\n  background-color: #ffffff;\n}\nh1 {\n  font-size: 18px;\n  font-weight: bold;\n  text-decoration: none;\n  padding-top: 0px;\n  color: #2970A6;\n}\na:link {\n    color: #2970A6;\n  text-decoration: none;\n}\na:hover {\n    color: #2970A6;\n  text-decoration: underline;\n}\np.buttonlink {\n  margin-bottom: 24px;\n}\n.copyright {\n  font-size: 12px;\n  color: #666666;\n  margin: 5px 5px 0px 30px;\n\n}\n.details {\n  font-size: 14px;\n  color: #969696;\n  border: none;\n  padding: 20px 20px 20px 20px;\n  margin: 0px 10px 10px 35px;\n}\n\n.shadow {\n  border: 3px solid #9f9f9f;\n  padding: 10px 25px 10px 25px;\n  margin: 10px 35px 0px 30px;\n  background-color: #ffffff;\n  width: 600px;\n\n  -moz-box-shadow: 3px 3px 3px #cccccc;\n  -webkit-box-shadow: 3px 3px 3px #cccccc;\n  box-shadow: 3px 3px 3px #cccccc;\n  /* For IE 8 */\n  -ms-filter: \"progid:DXImageTransform.Microsoft.Shadow(Strength=5, Direction=135, Color='cccccc')\";\n  /* For IE 5.5 - 7 */\n  filter: progid:DXImageTransform.Microsoft.Shadow(Strength=5, Direction=135, Color='cccccc');\n}\n.logo {\n  border: none;\n  margin: 5px 5px 0px 30px;\n}\n</style>\n</head>\n\n<body>\n<div class=\"logo\"></div><p>&nbsp;</p>\n<div class=\"shadow\">\n<h1>This Page Cannot Be Displayed</h1>\n\n\n<p>\nAuthentication is required to access the Internet using this system.\nA valid user ID and password must be entered when prompted.\n</p>\n\n\n\n<p>\nIf you have questions, please contact\nyour organization's network administrator \nand provide the codes shown below.\n</p>\n\n</div>\n\n<div class=\"details\"><p>\nDate: Wed, 12 Feb 2025 09:55:54 CST<br />\nUsername: <br />\nSource IP: 53.144.125.164<br />\nURL: POST http://127.0.0.1/api/generate<br />\nCategory: URL Filtering Bypassed<br />\nReason: UNKNOWN<br />\nNotification: PROXY_AUTH_REQUIRED\n</p></div>\n</body>\n</html>\n (status code: 407)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResponseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m write_query({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow many Employees are there?\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "Cell \u001b[1;32mIn[5], line 14\u001b[0m, in \u001b[0;36mwrite_query\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generate a SQL query using the refined prompt.\"\"\"\u001b[39;00m\n\u001b[0;32m      8\u001b[0m prompt \u001b[38;5;241m=\u001b[39m query_prompt_template\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m      9\u001b[0m     query\u001b[38;5;241m=\u001b[39mstate[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     10\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdb\u001b[38;5;241m.\u001b[39mdialect,\n\u001b[0;32m     11\u001b[0m     top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m\n\u001b[0;32m     12\u001b[0m )\n\u001b[1;32m---> 14\u001b[0m result \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39minvoke(prompt)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: extract_sql_query(result)}\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\MBMachineLearn\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:387\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    378\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    384\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[0;32m    385\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 387\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    388\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    389\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    390\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    391\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    392\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    393\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    394\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    395\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    396\u001b[0m         )\n\u001b[0;32m    397\u001b[0m         \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    398\u001b[0m         \u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m    399\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\MBMachineLearn\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:760\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    753\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    754\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    757\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    758\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    759\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_strings, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\MBMachineLearn\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:963\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[1;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    950\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[0;32m    951\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    961\u001b[0m         )\n\u001b[0;32m    962\u001b[0m     ]\n\u001b[1;32m--> 963\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_helper(\n\u001b[0;32m    964\u001b[0m         prompts, stop, run_managers, \u001b[38;5;28mbool\u001b[39m(new_arg_supported), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    965\u001b[0m     )\n\u001b[0;32m    966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[0;32m    967\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\MBMachineLearn\\Lib\\site-packages\\langchain_core\\language_models\\llms.py:784\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[1;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[0;32m    774\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[0;32m    775\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    776\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    781\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    783\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 784\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    785\u001b[0m                 prompts,\n\u001b[0;32m    786\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    787\u001b[0m                 \u001b[38;5;66;03m# TODO: support multiple run managers\u001b[39;00m\n\u001b[0;32m    788\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    789\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    790\u001b[0m             )\n\u001b[0;32m    791\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    792\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[0;32m    793\u001b[0m         )\n\u001b[0;32m    794\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    795\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\MBMachineLearn\\Lib\\site-packages\\langchain_ollama\\llms.py:288\u001b[0m, in \u001b[0;36mOllamaLLM._generate\u001b[1;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    286\u001b[0m generations \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m--> 288\u001b[0m     final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream_with_aggregation(\n\u001b[0;32m    289\u001b[0m         prompt,\n\u001b[0;32m    290\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    291\u001b[0m         run_manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[0;32m    292\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    293\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    294\u001b[0m     )\n\u001b[0;32m    295\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([final_chunk])\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\MBMachineLearn\\Lib\\site-packages\\langchain_ollama\\llms.py:256\u001b[0m, in \u001b[0;36mOllamaLLM._stream_with_aggregation\u001b[1;34m(self, prompt, stop, run_manager, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_stream_with_aggregation\u001b[39m(\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    249\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    254\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m GenerationChunk:\n\u001b[0;32m    255\u001b[0m     final_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 256\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m stream_resp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_generate_stream(prompt, stop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    257\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stream_resp, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    258\u001b[0m             chunk \u001b[38;5;241m=\u001b[39m GenerationChunk(\n\u001b[0;32m    259\u001b[0m                 text\u001b[38;5;241m=\u001b[39mstream_resp[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m stream_resp \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    260\u001b[0m                 generation_info\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    261\u001b[0m                     \u001b[38;5;28mdict\u001b[39m(stream_resp) \u001b[38;5;28;01mif\u001b[39;00m stream_resp\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    262\u001b[0m                 ),\n\u001b[0;32m    263\u001b[0m             )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\MBMachineLearn\\Lib\\site-packages\\langchain_ollama\\llms.py:211\u001b[0m, in \u001b[0;36mOllamaLLM._create_generate_stream\u001b[1;34m(self, prompt, stop, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_generate_stream\u001b[39m(\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    207\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    208\u001b[0m     stop: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    210\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Union[Mapping[\u001b[38;5;28mstr\u001b[39m, Any], \u001b[38;5;28mstr\u001b[39m]]:\n\u001b[1;32m--> 211\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m    212\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_params(prompt, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    213\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\MBMachineLearn\\Lib\\site-packages\\ollama\\_client.py:168\u001b[0m, in \u001b[0;36mClient._request.<locals>.inner\u001b[1;34m()\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    167\u001b[0m   e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m--> 168\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mtext, e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39miter_lines():\n\u001b[0;32m    171\u001b[0m   part \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(line)\n",
      "\u001b[1;31mResponseError\u001b[0m: <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\"\n\"http://www.w3.org/TR/html4/loose.dtd\">\n<html>\n<head>\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n<title>Notification: Proxy Authorization Required</title>\n<style type=\"text/css\">\nbody {\n  font-family: Arial, Helvetica, sans-serif;\n  font-size: 14px;\n  color:#333333;\n  background-color: #ffffff;\n}\nh1 {\n  font-size: 18px;\n  font-weight: bold;\n  text-decoration: none;\n  padding-top: 0px;\n  color: #2970A6;\n}\na:link {\n    color: #2970A6;\n  text-decoration: none;\n}\na:hover {\n    color: #2970A6;\n  text-decoration: underline;\n}\np.buttonlink {\n  margin-bottom: 24px;\n}\n.copyright {\n  font-size: 12px;\n  color: #666666;\n  margin: 5px 5px 0px 30px;\n\n}\n.details {\n  font-size: 14px;\n  color: #969696;\n  border: none;\n  padding: 20px 20px 20px 20px;\n  margin: 0px 10px 10px 35px;\n}\n\n.shadow {\n  border: 3px solid #9f9f9f;\n  padding: 10px 25px 10px 25px;\n  margin: 10px 35px 0px 30px;\n  background-color: #ffffff;\n  width: 600px;\n\n  -moz-box-shadow: 3px 3px 3px #cccccc;\n  -webkit-box-shadow: 3px 3px 3px #cccccc;\n  box-shadow: 3px 3px 3px #cccccc;\n  /* For IE 8 */\n  -ms-filter: \"progid:DXImageTransform.Microsoft.Shadow(Strength=5, Direction=135, Color='cccccc')\";\n  /* For IE 5.5 - 7 */\n  filter: progid:DXImageTransform.Microsoft.Shadow(Strength=5, Direction=135, Color='cccccc');\n}\n.logo {\n  border: none;\n  margin: 5px 5px 0px 30px;\n}\n</style>\n</head>\n\n<body>\n<div class=\"logo\"></div><p>&nbsp;</p>\n<div class=\"shadow\">\n<h1>This Page Cannot Be Displayed</h1>\n\n\n<p>\nAuthentication is required to access the Internet using this system.\nA valid user ID and password must be entered when prompted.\n</p>\n\n\n\n<p>\nIf you have questions, please contact\nyour organization's network administrator \nand provide the codes shown below.\n</p>\n\n</div>\n\n<div class=\"details\"><p>\nDate: Wed, 12 Feb 2025 09:55:54 CST<br />\nUsername: <br />\nSource IP: 53.144.125.164<br />\nURL: POST http://127.0.0.1/api/generate<br />\nCategory: URL Filtering Bypassed<br />\nReason: UNKNOWN<br />\nNotification: PROXY_AUTH_REQUIRED\n</p></div>\n</body>\n</html>\n (status code: 407)"
     ]
    }
   ],
   "source": [
    "write_query({\"question\": \"How many Employees are there?\"})  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d7ac1d3-add3-4498-9735-a016a2f3c029",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def execute_query(state: State):\n",
    "    \"\"\"Execute SQL query.\"\"\"\n",
    "    execute_query_tool = QuerySQLDatabaseTool(db=db)\n",
    "    return {\"result\": execute_query_tool.invoke(state[\"query\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9adbace-1fd5-4b9c-ba46-d6b8dbf6e1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'result': '[(8,)]'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "execute_query({\"query\": \"SELECT COUNT(EmployeeId) AS EmployeeCount FROM Employee;\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2decc5-038f-42dd-8e38-a988649b218a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(state: State):\n",
    "    \"\"\"Answer question using retrieved information as context.\"\"\"\n",
    "    prompt = (\n",
    "        \"Given the following user question, corresponding SQL query, \"\n",
    "        \"and SQL result, answer the user question.\\n\\n\"\n",
    "        f'Question: {state[\"question\"]}\\n'\n",
    "        f'SQL Query: {state[\"query\"]}\\n'\n",
    "        f'SQL Result: {state[\"result\"]}'\n",
    "    )\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"answer\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f1cf33-cd55-4562-a3c8-06ece4a4285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence(\n",
    "    [write_query, execute_query, generate_answer]\n",
    ")\n",
    "graph_builder.add_edge(START, \"write_query\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b9a3b3-7895-4ca4-83a7-89c582b55d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"How many employee are there?\"}, stream_mode=\"updates\"\n",
    "):\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3db050-8ebd-4640-8392-dbdfb693dd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory, interrupt_before=[\"execute_query\"])\n",
    "\n",
    "# Now that we're using persistence, we need to specify a thread ID\n",
    "# so that we can continue the run after review.\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e639168a-f4f4-4d40-978c-b8402780ba14",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "c7a761a7-c1a2-4562-b274-46c586c595cc",
   "metadata": {},
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"How many employees are there?\"},\n",
    "    config,\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(step)\n",
    "\n",
    "try:\n",
    "    user_approval = input(\"Do you want to go to execute query? (yes/no): \")\n",
    "except Exception:\n",
    "    user_approval = \"no\"\n",
    "\n",
    "if user_approval.lower() == \"yes\":\n",
    "    # If approved, continue the graph execution\n",
    "    for step in graph.stream(None, config, stream_mode=\"updates\"):\n",
    "        print(step)\n",
    "else:\n",
    "    print(\"Operation cancelled by user.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b81886c-0b00-4d95-94e5-5eb5935187da",
   "metadata": {},
   "source": [
    "## Below is code for an agent instead of a chain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2905142-6fd5-4a3a-b4ea-590881e4357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "\n",
    "tools = toolkit.get_tools()\n",
    "\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675b88af-9b12-4c70-af64-9050cf6bdd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"dialect\", \"top_k\", \"input\"],\n",
    "    template=\"\"\"You are an agent designed to interact with a SQL database.\n",
    "Given an input question, create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer.\n",
    "Unless the user specifies a specific number of examples they wish to obtain, always limit your query to at most {top_k} results.\n",
    "You can order the results by a relevant column to return the most interesting examples in the database.\n",
    "Never query for all the columns from a specific table, only ask for the relevant columns given the question.\n",
    "You have access to tools for interacting with the database.\n",
    "Only use the below tools. Only use the information returned by the below tools to construct your final answer.\n",
    "You MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\n",
    "\n",
    "**Instructions:**\n",
    "- You MUST double check your query before executing it. If you get an error while executing a query, rewrite the query and try again.\n",
    "- DO NOT make any DML statements (INSERT, UPDATE, DELETE, DROP etc.) to the database.\n",
    "- **Always** use column names explicitly (e.g., `COUNT(EmployeeId) AS EmployeeCount` instead of `COUNT(*)`).\n",
    "- Do **not** explain the query.\n",
    "- Do **not** include any additional text.\n",
    "- Do **not** describe database tables unless explicitly asked.\n",
    "- Only return the final SQL query.\n",
    "- Always limit results to **{top_k}** unless specified otherwise.\n",
    "- Do **not** add anything to the end of the table name (e.g 'Employee' instead of 'Employees')\n",
    "\n",
    "\n",
    "\n",
    "To start you should ALWAYS look at the tables in the database to see what you can query.\n",
    "Do NOT skip this step.\n",
    "Then you should query the schema of the most relevant tables.\n",
    "Question: {input}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e7f35a-485d-4e49-b6da-98d696bc7ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question =  \"Which country's customers spent the most?\"\n",
    "\n",
    "system_message = prompt_template.format(dialect=\"SQLite\", top_k=5, input = user_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a3b254-db9b-4ed8-93e8-163f67059e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ... (your database connection and LLM initialization) ...\n",
    "\n",
    "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
    "tools = toolkit.get_tools()\n",
    "\n",
    "# Refine tool descriptions (VERY IMPORTANT for ZERO_SHOT_REACT_DESCRIPTION):\n",
    "for tool in tools:\n",
    "    if tool.name == \"QuerySQLDatabaseTool\":\n",
    "        tool.description = \"\"\"\n",
    "        Use this tool to execute SQL queries against the database. \n",
    "        Input: A detailed and CORRECT SQL query.\n",
    "        Output: The result from the database.\n",
    "        IMPORTANT: Before using this tool, ALWAYS use the 'QuerySQLCheckerTool' to validate your query.\n",
    "        If the query is incorrect, the tool will return an error message.\n",
    "        If you encounter an issue like 'Unknown column...', use the 'InfoSQLDatabaseTool' to get the correct table fields.\n",
    "        \"\"\"\n",
    "    elif tool.name == \"InfoSQLDatabaseTool\":\n",
    "        tool.description = \"\"\"\n",
    "        Use this tool to get information about the database schema and sample rows.\n",
    "        Input: A comma-separated list of table names.\n",
    "        Output: The schema and sample rows for those tables.\n",
    "        Use this tool to understand the database structure or to find the correct column names for your queries.\n",
    "        Call the 'ListSQLDatabaseTool' first to know what tables are available.\n",
    "        \"\"\"\n",
    "    elif tool.name == \"ListSQLDatabaseTool\":\n",
    "        tool.description = \"\"\"\n",
    "        Use this tool to get a list of available tables in the database.\n",
    "        Input: None.\n",
    "        Output: A list of table names.\n",
    "        Use this tool before using 'InfoSQLDatabaseTool' to make sure the tables exist.\n",
    "        \"\"\"\n",
    "    elif tool.name == \"QuerySQLCheckerTool\":\n",
    "        tool.description = \"\"\"\n",
    "        Use this tool to check if your SQL query is correct BEFORE executing it with 'QuerySQLDatabaseTool'.\n",
    "        Input: The SQL query you want to check.\n",
    "        Output: The original query if it is correct, or a corrected query if there were mistakes.\n",
    "        ALWAYS use this tool first.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,  # Your Ollama LLM instance\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    prompt=system_message,\n",
    ")\n",
    "\n",
    "# Example usage:\n",
    "agent.invoke( \"Which country's customers spent the most?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523a7fcc-64c9-4496-b436-410a4d1eaa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "agent.invoke(\"Describe the playlisttrack table\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de63dcc-a803-4a88-a7f1-46e9affde3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.invoke(\"What are 10 track names and their artists?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197c0f6c-8d93-46da-9c31-1a87e49e0b47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
